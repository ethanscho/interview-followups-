{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Training\n",
    "\n",
    "### 여러 대의 물리 머신을 이용해 하나의 모델을 학습 시키는 방법으로는 어떤 것들이 있을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크게 In-graph replication과 Between-graph replication로 나뉨\n",
    "\n",
    "1. In-graph replication\n",
    "모델의 레이어들을 각 GPU에 할당하는 방식\n",
    "\n",
    "2. Between-graph replication\n",
    "각 머신이 graph를 통째로 가지고 있고 서로 다른 mini-batch를 학습시키고 합치는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between-graph 예시\n",
    "\n",
    "<img src='img/between_graph.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between-graph 방식은 parameter server를 사용하는 방식과 ring-allreduce 방식으로 나뉨\n",
    "\n",
    "(1) Parameter Server\n",
    "\n",
    "중앙에 parameter server가 parameter update를 진행하고 나머지 머신들은 gradient를 계산하는 역할만 한다.\n",
    "크게 동기/비동기 방식으로 나눌 수 있다.\n",
    "\n",
    "<img src='img/parameter_server.png'/>\n",
    "\n",
    "(2) Ring-Allreduce\n",
    "\n",
    "<img src='img/ring_allreduce.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ring-Allreduce가 제일 병렬화가 좋다고 함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
